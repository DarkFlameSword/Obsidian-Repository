---
date: 2025-10-19
author:
  - Siyuan Liu
tags:
  - FIT5215
---

![[Pasted image 20251019140633.png]]
### 1. 视频逐帧分类 (Video classification at frame level) -> 匹配 D (many to many)

- **任务描述：** 对视频中的每一帧进行分类。例如，判断每一帧画面中是否包含某个物体。
    
- **输入 (Input):** 一个视频，也就是一个**图像帧的序列** (`x_1, x_2, x_3, ...`)。这是一个“多输入”(many) 的情况。
    
- **输出 (Output):** 对应每一帧的分类标签 (`y_1, y_2, y_3, ...`)。例如，`y_1` 是对第1帧的分类，`y_2` 是对第2帧的分类，以此类推。这也是一个“多输出”(many) 的情况。
    
- **为什么是 D：** 模型在处理第 `t` 帧 (`x_t`) 时，就会立即生成该帧对应的输出 `y_t`。输入和输出序列是同步的，长度也完全一样。这与结构 D 的模式（每个 `x` 都有一个直接对应的 `y`）完全吻合。
    

### 2. 情感分析 (Sentiment analysis) -> 匹配 A (many to one)

- **任务描述：** 判断一整段文字（如一条电影评论）的情感是积极的、消极的还是中性的。
    
- **输入 (Input):** 一个**单词的序列** (`x_1, x_2, x_3, ...`)，例如 "这部电影太棒了！"。这是一个“多输入”(many) 的情况。
    
- **输出 (Output):** **一个**单一的分类结果 (`y`)，例如“积极”。这是一个“单输出”(one) 的情况。
    
- **为什么是 A：** 模型必须读完整个句子，将所有单词的信息通过隐藏状态 `h` 一层层传递并累积起来，直到最后一个单词。最后，模型根据包含整句话信息的最终隐藏状态，做出一个总结性的判断。这正是结构 A 所描述的：处理一个序列，最后只给出一个输出。
    

### 3. 机器翻译 (Machine translation) -> 匹配 C (many to many)

- **任务描述：** 将一种语言的句子翻译成另一种语言的句子。
    
- **输入 (Input):** 源语言的**单词序列** (`x_1, x_2, x_3, ...`)，例如 "I am a student"。这是一个“多输入”(many) 的情况。
    
- **输出 (Output):** 目标语言的**单词序列** (`y_1, y_2, y_3, ...`)，例如 "我 是 一个 学生"。这是一个“多输出”(many) 的情况。
    
- **为什么是 C (而不是 D)：** 机器翻译的复杂性在于，输入和输出序列的长度往往不同，且语法结构和语序也可能完全不同。模型必须**先完整地读取并理解整个输入句子**（这个过程称为“编码器” Encoder），形成一个代表全句意义的“上下文向量”(context vector)。然后，再基于这个上下文向量**开始生成输出句子**（这个过程称为“解码器” Decoder）。结构 C 完美地展示了这种先“编码”输入序列，再“解码”输出序列的模式。
    

### 4. 图像描述生成 (Image captioning) -> 匹配 B (one to many)

- **任务描述：** 为给定的图像生成一段描述性的文字。
    
- **输入 (Input):** **一张**图像。通常，这张图像会先通过一个卷积神经网络（CNN）提取特征，生成一个固定长度的向量。这个向量作为 RNN 的**唯一输入** (`x`)。这是一个“单输入”(one) 的情况。
    
- **输出 (Output):** 一个描述图像的**单词序列** (`y_1, y_2, y_3, ...`)，例如 "一只猫正躺在地毯上"。这是一个“多输出”(many) 的情况。
    
- **为什么是 B：** 模型接收一次性的图像信息输入，然后利用这个信息作为初始状态，一步步地生成描述文字的每一个单词。这就像你看到一张图片后，开始构思并说出一个完整的句子。这与结构 B 的模式（一个输入，生成一个序列输出）完全吻合。


