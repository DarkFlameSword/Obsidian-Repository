---
date: 2025-10-05
author:
  - Siyuan Liu
tags:
  - FIT5215
---
# Model Fine-Tuning
![[Pasted image 20251019220020.png]]
**理解：**
在预训练模型的基础上，使用**特定领域的数据**继续训练，调整模型参数以适应特定任务


**微调的详细流程**

我们以一个具体的例子来说明：你想做一个**电影评论情感分类器**（判断评论是“正面”还是“负面”）
1. **第一步：选择一个合适的预训练模型**
    - 你会选择一个强大的**语言模型**，比如 **BERT** 或 **GPT** 的某个版本。这个模型已经在维基百科、书籍等海量文本上进行了预训练，已经懂得了英语（或中文）的语法、语义和常识
2. **第二步：准备你的特定数据集**
    - 你需要一个**有标签**的数据集，例如 2000 条电影评论，每一条都标注了“正面”或“负面”
3. **第三步：修改模型“头部” (Modify the Model Head)**
    - 原始的 BERT 模型可能被训练来做“填词”或“判断下一句”的任务，它的输出层（“头部”）不适合做情感分类
    - 你需要**移除**这个原始的“头部”，换上一个适合你任务的新“头部”。对于情感分类，这个新“头部”通常就是一个简单的**线性层 (Linear Layer)**，它的输出维度是 2（代表“正面”和“负面”两个类别）
4. **第四步：进行微调训练**
    - 将你的 2000 条带标签的评论数据喂给修改后的模型
    - 关键点：使用一个**非常小的学习率 (low learning rate)**
    - **原因**：预训练模型的权重已经非常好了，你不想在训练中用一个大的学习率彻底“摧毁”这些宝贵的知识。你只想在它的基础上进行**微小的、精细的调整**，让它适应你“电影评论情感”这个特定领域
    - （可选高级操作）：有时，为了进一步保护预训练知识，人们会**冻结 (freeze)** 模型的大部分底层网络，只训练最后几层和新加的“头部”

# Model Fine-Tuning with Additional Components
![[Pasted image 20251019220031.png]]

# Model Fine-Tuning with Prompts
![[Pasted image 20251019220042.png]]


# Model Fine-Tuning with Adapters
![[Pasted image 20251019220225.png]]


# Model Fine-Tuning with Additional LoRA
![[Pasted image 20251019220235.png]]
