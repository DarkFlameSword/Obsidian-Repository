---
date: 2025-10-19
author:
  - Siyuan Liu
tags:
  - FIT5215
---
# Perceptron
**核心思想**：感知器是神经网络最基本、最古老的组成单元，就像一个只会做“是”或“否”二元决策的神经元。

**工作流程（一个比喻）：** 想象一下，你要决定“今天是否要去海滩”。你会考虑几个因素（输入）：

1. **天气好吗？** (输入 `x₁`)
    
2. **朋友有空吗？** (输入 `x₂`)
    
3. **我有作业吗？** (输入 `x₃`)
    

作为一个简单的决策者，你的大脑会这样做：

1. **分配权重 (Weights)**：你觉得“天气”最重要（权重 `w₁`=0.6），“朋友”次之（权重 `w₂`=0.3），“作业”影响最小（权重 `w₃`=0.1）。权重代表了每个输入的重要性。
    
2. **计算加权和**：你把所有因素的“证据”加起来。`总分 = (天气 * w₁) + (朋友 * w₂) + (作业 * w₃)`。
    
3. **做出决策 (Activation Function)**：你心里有一个“决策门槛”（Threshold）。如果总分超过这个门槛，你就决定**去**（输出=1）；否则，就**不去**（输出=0）。
    

**感知器的能力与缺陷：**

- **能力**：它能解决**线性可分 (Linearly Separable)** 的问题。也就是说，它只能画**一条直线**，来把“去海滩”和“不去海滩”的各种情况分开。
    
- **致命缺陷**：它无法解决**非线性**问题。最著名的例子就是 **“异或 (XOR)”问题**。你无法用一条直线把 XOR 问题的四个点完美地分成两类。这直接导致了神经网络的第一次“寒冬”。


---
# Multi-Layer Perceptron
**核心思想**：既然一个决策者（感知器）能力有限，那我们就组建一个“委员会”，让多个决策者协同工作，解决更复杂的问题。

**工作流程（委员会的比喻）：**

一个 MLP 就是一个由多个感知器（现在我们称它们为“神经元”）分层组成的网络。它至少有三层：

1. **输入层 (Input Layer)**：接收最原始的信息。就像委员会的秘书，负责收集所有的原始数据（天气、朋友、作业等）。
    
2. **隐藏层 (Hidden Layers)**：这是 MLP 的**核心**。它是由多个神经元组成的“专家小组”。
    
    - 第一层的专家们（比如3个神经元）并不直接做最终决定。他们各自从不同的角度分析原始数据，并得出自己的**初步结论**。比如，神经元A可能专门负责判断“今天是否适合户外活动”，神经元B可能负责判断“今天社交的意愿有多强”。
        
    - 如果还有第二层隐藏层，那么这一层的专家们会根据第一层专家的“初步结论”，进行更高级、更抽象的分析。
        
3. **输出层 (Output Layer)**：这是委员会的“最终决策者”。它会综合所有隐藏层专家的意见，并做出最终的、复杂的决策（比如分类到多个类别，或者给出一个具体的数值）。
    

**MLP 与感知器的关键区别：**

1. **结构**：MLP 有一个或多个**隐藏层**，而感知器没有。
    
2. **解决非线性问题**：通过组合多个神经元（每个神经元画一条直线），MLP 可以创造出复杂的、非线性的决策边界（比如曲线、多边形），从而轻松解决 **XOR** 这类问题。**这是 MLP 最重要的能力提升**。
    
3. **激活函数**：MLP 中的神经元通常使用**平滑、可微分**的非线性函数（如 **Sigmoid** 或 **ReLU**），而不仅仅是简单的 0/1 阶跃函数。这使得模型可以使用**反向传播 (Backpropagation)** 算法进行高效的训练。