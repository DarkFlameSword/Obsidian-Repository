---
date: 2025-08-10
author:
  - Siyuan Liu
tags:
  - FIT5215
aliases:
  - summary
---
# Architecture
![[Pasted image 20250810173513.png]]
## Input Layer
==作用:==

## Convolutional Layer
==作用:==
Feature Extraction

==步骤:==
1. **卷积核 (Kernel)**：它是一个很小的、带有权重值的矩阵（比如 3x3 或 5x5）。不同的权重组合让它能探测不同的特征。例如，一个卷积核可能被训练来专门探测“垂直边缘”，另一个则探测“红色块”。
2. **滑动计算 (Convolution)**：这个卷积核会在整个输入图像上从左到右、从上到下滑动。在每一个位置，它都会覆盖一小块图像区域。
3. **点积求和**：卷积核会与它覆盖的图像区域进行**元素对应相乘，然后求和**。这个求和后的结果，就成为了输出**特征图 (Feature Map)** 中的一个像素值。
4. **生成特征图**：卷积核滑完整张图片后，就生成了一张新的“特征图”。这张图上的每个点，都代表了原始图像对应位置**是否存在该卷积核所探测的特征**。值越大，代表特征越明显
![[Pasted image 20250810192009.png]]
$$
W_o = \lfloor \frac{W_i - K_w + 2P}{S_w} \rfloor + 1 \;\;\;\;\;\;\; H_o = \lfloor \frac{H_i - K_h + 2P}{S_h} \rfloor + 1
$$
- `Wi,Hi`: 输入图像尺寸
- `Wo,Ho`: 输出图像尺寸
- `Kw,Kh`: 卷积核宽, 高
- `Sw,Sh`: 步长核宽, 高
-  `P`: 填充
## Activation Layer
==作用:==
Introduce Non-linearity
## Pooling Layer
==作用:==
1. **降维/减少计算量 (Dimensionality Reduction)**：池化层可以显著减小特征图的尺寸（高度和宽度），从而减少后续层的参数数量和计算量，防止过拟合。
2. **通过subsample保持特征不变性 (Invariance)**：它使模型对特征在图像中的微小位移不那么敏感。比如，无论一只猫的眼睛在图像的左上角还是稍微偏右一点，池化后的结果都很相似。这增强了模型的鲁棒性。

==步骤:==
1. **窗口滑动**：一个 2x2 的窗口在特征图上滑动（通常步长为2，即窗口不重叠）。
2. **取最大值**：在窗口覆盖的区域内（比如 4 个像素），只保留**最大的那个值**，把其他值都丢掉。
3. **尺寸减半**：经过 2x2 的最大池化后，特征图的高度和宽度都会减半，总大小变为原来的 1/4

### Global Pooling Layer
相较于普通的池化层, 全局池化的池化窗口不需要移动, 而是将整个input当作池化窗口

**好处**:
**参数更少**
- 传统 CNN 在最后一般会接全连接层（FC）来变成分类 logits，参数量大。
- Global Pooling 可以直接把特征图缩成 (C,1,1)，接 softmax 就能分类 → 极大减少参数。
**减少过拟合**
- 因为没有庞大的全连接层，模型更不容易过拟合。
**平移不变性**
- 位置不重要，整个图像的统计特征（最大值/均值）被保留下来
#### Global Average Pooling
#### Global Max Pooling


### Pooling Type
#### Max Pooling
取池化窗口中最大的值为特征值
#### Average Pooling
计算池化窗口中的平均值, 以该值为特征值
## Fully Connected Layer
==作用:==
在经过多轮“卷积-激活-池化”的特征提取后，我们得到了一系列高度抽象的特征图, 将这些最终的特征进行**整合和映射**，最终完成分类任务

==步骤:==
1. **展平 (Flatten)**：首先，将前面池化层输出的所有二维特征图“拉直”，变成一个长长的一维向量。
2. **连接**：这个层中的每一个神经元，都与前一层（展平后的向量）的所有神经元相连接（这也是“全连接”这个名字的由来）。
3. **加权求和**：通过一系列矩阵乘法和激活函数，全连接层对这些高度抽象的特征进行加权求和，学习特征之间的非线性组合，最终将它们映射到最终的类别得分上。
![[Pasted image 20250810192747.png]]

## Output Layer


# Receptive Field
![[Pasted image 20250901151503.png]]
==Neurons on higher layers have larger receptive fields (patches) on input images==



