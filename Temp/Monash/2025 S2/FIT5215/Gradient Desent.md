---
date: 2025-08-22
author:
  - Siyuan Liu
tags:
  - FIT5215
aliases:
  - base
---
$θt+1​=θt​−η∇θ​J(θt​)$
- **θt​**：第 ttt 次迭代时的参数（模型的权重和偏置）。
- **θt+1\theta_{t+1}θt+1​**：更新后的参数，也就是下一次迭代用的参数。
- **η\etaη**：学习率（learning rate），一个超参数，控制每次更新的步长大小。
- **J(θt)J(\theta_t)J(θt​)**：损失函数（loss function），衡量当前参数下模型预测与真实标签的差距。
- **∇θJ(θt)\nabla_{\theta} J(\theta_t)∇θ​J(θt​)**：损失函数对参数的梯度（gradient），告诉我们“在当前位置，往哪个方向能最快增加损失”。

可以把损失函数$J(\theta)$想象成一座山：

- 你站在某个位置 $\theta_i​$
    
- 梯度告诉你“往哪个方向坡度最大”。
    
- 为了下山（最小化损失），你要往反方向走。
    
- 每走一步就是更新一次参数，直到找到谷底（最优解）。


假设损失函数是简单的二次函数：

$J(θ)=\theta^2$

那么：

$∇θ​J(θ)=2θ$

更新公式：

$θt+1​=θt​−η(2θt​)=θt​(1−2η)$

如果 $\eta$ 选得合适（比如 0.1），那么 $\theta$ 会逐渐接近 0（最优解）。