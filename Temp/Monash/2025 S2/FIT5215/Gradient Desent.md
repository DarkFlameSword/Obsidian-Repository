---
date: 2025-08-22
author:
  - Siyuan Liu
tags:
  - FIT5215
aliases:
  - base
---
# Formula
$$θt+1​=θt​−η∇θ​J(θt​)$$
- $θt​$：第 t 次迭代时的参数（模型的权重和偏置）
- $\theta_{t+1}$：更新后的参数，也就是下一次迭代用的参数
- $\eta$：学习率（learning rate），一个超参数，控制每次更新的步长大小
- J$(\theta_t)$：损失函数（loss function），衡量当前参数下模型预测与真实标签的差距。
- $\nabla_{\theta} J(\theta_t)$：损失函数对参数的梯度（gradient），告诉我们“在当前位置，往哪个方向能最快增加损失”
## 理解
可以把损失函数$J(\theta)$想象成一座山：
- 你站在某个位置 $\theta_i​$
- 梯度告诉你“往哪个方向坡度最大”
- 为了下山（最小化损失），你要往反方向走
- 每走一步就是更新一次参数，直到找到谷底（最优解）

假设损失函数是简单的二次函数：
$J(θ)=\theta^2$
那么：
$∇θ​J(θ)=2θ$
更新公式：
$θt+1​=θt​−η(2θt​)=θt​(1−2η)$
如果 $\eta$ 选得合适（比如 0.1），那么 $\theta$ 会逐渐接近 0（最优解）
# 如何计算下一个优化后的gradient
![[Pasted image 20250822171531.png]]
# 深度神经网络的训练目标
## 总体目标

$$min⁡_θ L(D;\theta)   =  \frac{1}{N}∑_{i=1}^N \ell(xi,yi;\theta)$$

- $\theta$：模型参数（权重、偏置等）
- $D=\{(xi,yi)\}_{i=1}^N$ ：数据集，有 N 个样本
- $\ell(x_i, y_i; \theta)$：对单个样本的损失
- **目标**：找到能使平均损失最小的参数 $\theta$

## 单样本的损失函数

$$\ell(x_i, y_i; \theta) \;=\; - \log \, p(y=y_i \mid x_i)$$

这就是 **交叉熵损失 (cross-entropy loss)**，它衡量模型预测的概率分布与真实标签之间的差距
## 分类任务里的概率模型

$$p(y=y_i \mid x_i) \;=\; \frac{\exp\{ h^{(L)}_{y_i}(x_i) \}}{\sum_{m=1}^M \exp\{ h^{(L)}_m(x_i) \}}$$

- $h^{(L)}_m(x_i)$：神经网络最后一层（第 L 层）的输出，即 `logits`，对应第 m 个类别。
- `Softmax` 函数：把 logits 转换成概率分布（所有类别概率之和为 1）
## 总结
- 我们的目标是：**让真实类别的概率尽可能接近 1**，同时让其他类别的概率变小。
- 交叉熵就是通过最大化正确类别概率（等价于最小化负对数似然）来实现的。
# 梯度下降的更新公式
## 梯度下降更新公式
$$\theta_{t+1} = \theta_t - \eta \nabla_{\theta} L(D; \theta_t)$$
- $\theta_t​$：第 t 次迭代的参数
- $\eta > 0$：学习率（learning rate），控制更新步长
- $L(D; \theta_t)$：在整个训练集 D 上的平均损失

---
## 损失函数的梯度
因为损失函数是所有样本的平均：
$$L(D; \theta) = \frac{1}{N} \sum_{i=1}^N \ell(x_i, y_i; \theta)$$
所以它的梯度就是：
$\nabla_{\theta} L(D; \theta_t) = \frac{1}{N} \sum_{i=1}^N \nabla_{\theta} \ell(x_i, y_i; \theta_t)$
也就是说，要计算总损失的梯度，必须把 **每个样本的梯度都算一遍**，再取平均

---
## 参数更新公式展开
带入损失函数梯度：
$$\theta_{t+1} = \theta_t - \eta \cdot \frac{1}{N} \sum_{i=1}^N \nabla_{\theta} \ell(x_i, y_i; \theta_t)$$
- 这就是 **批量梯度下降 (Batch Gradient Descent)**。
- 每次更新都用 **全部 N 个样本** 计算梯度。

---

## 计算复杂度

- 数据集大小：N
- 每次更新需要计算所有样本的梯度 → 计算量是 O(N)
- 如果 N 很大（比如百万级数据），每次更新会非常慢。

---
## 结论

- 梯度下降就像“下山”找谷底：
    - $\nabla_{\theta}$= 梯度，告诉你坡度的方向
    - $-\eta$= 负号 + 学习率，保证你往“下坡”方向走
- 但如果你每次都要“看遍整个山”才能走一步（即计算所有样本梯度），那就很耗时。

# Stochastic Gradient Descent(SGD)
**随机抽取 1 个样本** $(x_j, y_j)$，近似当前梯度：
$$\theta_{t+1}​=\theta_t​−\eta \cdot \nabla_{\theta}\ell(xi​,yi​;\theta_t​)$$这样每次更新都 **非常快**，只需一个样本, 但缺点是：更新方向比较“抖动”，不如全量梯度那么稳定

==举例==
![[Pasted image 20250822174832.png]]
![[Pasted image 20250822182635.png]]

|Optimizer|understand|
|---|---|
|**BGD**|像一个人走路前要看完整张地图（全量数据），走得稳，但慢|
|**SGD**|每次只看一个路标（一个样本），走得快，但路线有点抖动|
|**Mini-batch SGD**| 折中方案，比如每次用 32 个样本，既快又相对稳定|
## SGD with momentum

1. **采样一个 mini-batch**

$\{(x_1, y_1), (x_2, y_2), \dots, (x_b, y_b)\}$
这里 b 是 batch size。

2. **计算梯度的 mini-batch 平均值**
$g = \frac{1}{b}\sum_{i=1}^{b} \nabla_\theta \, l(f(x_i;\theta), y_i)$
- $l(\cdot)$：损失函数
- $f(x_i;\theta)$：模型预测
- g：当前 batch 的平均梯度

2. **更新动量（velocity）**
    

$v \leftarrow \alpha v + (1-\alpha) g$

- v：动量（类似“速度”）
- $\alpha \in [0,1))$：动量系数（常见 0.9）
- **解释**：新的速度是“历史速度的一部分 + 当前梯度的一部分”
    - 如果 $\alpha$ 很大（接近 1），说明更重视历史方向
    - 如果 $\alpha$ 较小，说明更重视当前梯度

4. **更新参数**
$\theta \leftarrow \theta - \eta v$
- $\eta > 0$：学习率
- 参数的更新方向 = “动量方向”
- **好处**：不会被单个 batch 的噪声干扰太大，更新更平滑、更快收敛

引入一个“速度项” $v_t$：

$$v_{t+1} = \mu v_t - \eta \nabla_\theta L(\theta_t)$$
$$\theta_{t+1} = \theta_t + v_{t+1}$$
然后我们就得到:
$$\theta_{t+1} = \theta_t + (\mu v_t - \eta \nabla_\theta L(\theta_t))$$
其中：
- $v_t​$：类似“速度”，记录之前梯度的累计趋势
- $\mu \in [0,1)$：动量系数（常用 0.9）
- $\eta$：学习率
- $\nabla_\theta L(\theta_t)$：当前梯度

==理解:==
- **普通 SGD**：小球每次只看当前位置的坡度，容易在谷底左右震荡。
- **SGD with momentum**：小球有“惯性”，会把之前的梯度方向也考虑进去，更快滚到谷底，而且震荡小
# AdaGrad
==理解:==
### 核心思想：用一个生动的比喻开始

想象你在一个崎岖的山谷中试图走到谷底（损失函数的最小值）。

- **标准梯度下降 (SGD)**：你每一步的大小（学习率）都是固定的。如果山谷在一个方向上非常陡峭，而在另一个方向上非常平缓，你固定的步长可能会在陡峭方向上来回震荡，同时在平缓方向上前进缓慢。
    
- **AdaGrad (Adaptive Gradient Algorithm)**：你变得更“智能”了。你会记录下你走过的每一步历史。
    
    - 对于那些你**经常移动**的方向（梯度一直很大的方向，即陡峭的坡），你会变得更加谨慎，**减小步长**，以防走过头。
    - 对于那些你**很少移动**的方向（梯度一直很小的方向，即平缓的坡），你会变得更加大胆，**增**大步长，以加速探索。

简而言之，AdaGrad 的核心思想是：**为每一个参数（Parameter）自适应地调整其学习率**。更新频繁的参数，其学习率会衰减得更快；更新稀疏的参数，其学习率会衰减得更慢。

我们来看一下参数更新的公式。对于模型中的第 `i` 个参数 `θ_i`，在时间步 `t` 的更新规则如下：

1. **计算当前梯度**： gt,i=∇θiJ(θt,i)
    
    - J(θ) 是损失函数。
    - gt,i 是在时间步 `t` 时，损失函数对参数 `θ_i` 的梯度。
2. **累积历史梯度平方和**： Gt,ii=Gt−1,ii+gt,i2
    
    - Gt,ii 是一个对角矩阵（或者更简单地，一个向量），存储了从开始到当前时间步 `t`，第 `i` 个参数梯度的平方之和。这个值会随着训练的进行而**单调递增**。
3. **更新参数**： θt+1,i=θt,i−ηGt,ii+ϵ⋅gt,i
    
    - θt+1,i 是更新后的参数值。
    - η (eta) 是一个**全局的初始学习率**，是一个需要手动设置的超参数。
    - ϵ (epsilon) 是一个非常小的正数（例如 `1e-8`），用于防止分母为零，起到平滑作用。
    - 关键部分是 ηGt,ii+ϵ。这部分就是参数 `θ_i` **在当前时间步的有效学习率**。

#### 2. 公式解读

- 当一个参数 `θ_i` 的历史梯度很大时（即 Gt,ii 的值很大），分母 Gt,ii+ϵ 也会很大，从而导致其有效学习率变得很小。
- 反之，如果一个参数的历史梯度很小（例如在稀疏数据中，某个特征很少出现，其对应参数的梯度大部分时间为零），Gt,ii 的值会很小，其有效学习率会相对较大，从而在它偶尔获得梯度时能够进行一次较大的更新。
# RMSProp
# Adam
# Back Propagation in feed
