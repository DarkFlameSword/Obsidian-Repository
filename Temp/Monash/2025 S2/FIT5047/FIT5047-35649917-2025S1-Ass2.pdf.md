# Q1
## a
$$\phi_1 = (((A ∨ (B → C)) ∧ (¬C ∨ D)) → ((A → D) ∨ (C ↔ E)))$$
**Conclusion:**
satisfiable but not valid

**Justification:**
- if `A = true, D = true`, then the equivalence holds
- if `A = true, D = false, C = false, E =true`, then the equivalence fails

---

$$\phi_2 = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ F) ↔ (A ∧ B))$$
**Conclusion:**
satisfiable but not valid

**Justification:**
- If `A = true, B = true, C = flase, D = false, F = false`, the equivalence fails
- If `A = true, B = true, D = false, F = true`, the equivalence holds

---

$$\phi_3 = ((A ↔ B) ∨ (C → D)) ∧ ((¬A ∨ ¬D) → (F ∧ ¬G))$$
**Conclusion:**
satisfiable but not valid

**Justification:**
- If `A = true, D = false`, the equivalence fails
- If `F = true, G = false`, the equivalence holds

---
## b

$$\phi_1 = (((A ∨ (B → C)) ∧ (¬C ∨ D)) → ((A → D) ∨ (C ↔ E)))$$
**Converting CNF steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$: 
$$\lnot \left( \left[ A \lor (\lnot B \lor C) \right] \land (\lnot C \lor D) \right) \lor \left( (\lnot A \lor D) \lor \left[ (\lnot C \land E) \lor ( C \land \lnot E) \right] \right)$$
2. CNF: 
$$\begin{aligned}
&φ₁ = [¬(A ∨ ¬B ∨ C) ∨ ¬(¬C ∨ D)] ∨\\
&[(¬A ∨ D ∨ ¬C ∨ E) ∧ (¬A ∨ D ∨ ¬E ∨ C)]\\
&φ₁ = [(¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)] ∨\\
&[(¬A ∨ D ∨ ¬C ∨ E) ∧ (¬A ∨ D ∨ ¬E ∨ C)]\\\\
& \text{if we assume:}\\
& A₁ = (¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)\\
& B₁ = (¬A ∨ D ∨ ¬C ∨ E)\\
& B₂ = (¬A ∨ D ∨ ¬E ∨ C)\\
& \text{So we have:}\; φ₁ = A₁ ∨ (B₁ ∧ B₂)\\\\
& \text{Using the distributive law:}\; φ₁ = (A₁ ∨ B₁) ∧ (A₁ ∨ B₂)\\
& φ₁ = [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬C ∨ E)] ∧\\
& [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬E ∨ C)]\\\\
& φ₁ = [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬C ∨ E)] ∧\\
& [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬E ∨ C)]\\\\\\
& \text{Final CNF Result:}\\
&φ₁ = (¬A ∨ B ∨ D ∨ E) ∧ (¬A ∨ D ∨ ¬E ∨ C) ∧ (¬A ∨ ¬C ∨ E)
\end{aligned}$$
**Horn clauses identification:**
1. (¬A ∨ ¬C ∨ E) is Horn clause (contains only one positive literals)

---

$$\phi_2 = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ F) ↔ (A ∧ B))$$
**Converting CNF steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$: 
$$\begin{aligned}
& φ₂ = (((¬A ∧ B) ∨ (¬C ∨ D)) ∧ (¬E ∨ A)) \rightarrow \\
& (((¬D ∨ F) \rightarrow (A ∧ B)) ∧ ((A ∧ B) \rightarrow (¬D ∨ F)))\\\\
&φ₂ = ¬(((¬A ∧ B) ∨ (¬C ∨ D)) ∧ (¬E ∨ A)) ∨ \\
&(((D ∧ ¬F) ∨ (A ∧ B)) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F))\\
\end{aligned}$$
2. CNF: 
$$\begin{aligned}
& \text{Using the De Morgan's law:}\\
& φ₂ = (((A ∨ ¬B) ∧ (C ∧ ¬D)) ∨ (E ∧ ¬A)) ∨ \\
& (((D ∧ ¬F) ∨ (A ∧ B)) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F)) \\\\
& \text{Using the distributive law:}\\
& [(A ∨ ¬B ∨ E) ∧ (A ∨ ¬B ∨ ¬A) ∧ (C ∨ E) ∧ \\
&(C ∨ ¬A) ∧ (¬D ∨ E) ∧ (¬D ∨ ¬A)] ∨ [(D ∨ A) ∧\\
&(D ∨ B) ∧ (¬F ∨ A) ∧ (¬F ∨ B) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F)]\\\\
& \text{Final CNF Result:}\\
& φ₂ = (A ∨ ¬B ∨ E ∨ D) ∧ (A ∨ E ∨ D ∨ B) ∧ (A ∨ ¬B ∨ E ∨ ¬F) ∧ \\
& (A ∨ E ∨ ¬F ∨ B) ∧ (¬B ∨ E ∨ ¬A ∨ ¬D ∨ F) ∧\\
& (C ∨ E ∨ D ∨ A) ∧ (C ∨ E ∨ D ∨ B) ∧ (C ∨ E ∨ ¬F ∨ A) ∧ \\
& (C ∨ E ∨ ¬F ∨ B) ∧ (C ∨ E ∨ ¬A ∨ ¬B ∨ ¬D ∨ F) ∧\\
& (C ∨ D) ∧ (C ∨ ¬A ∨ D ∨ B) ∧ (C ∨ ¬F) ∧ \\
& (C ∨ ¬A ∨ ¬F ∨ B) ∧ (C ∨ ¬A ∨ ¬B ∨ ¬D ∨ F) ∧\\
& (E ∨ A) ∧ (E ∨ D ∨ B) ∧ (¬D ∨ E ∨ ¬F ∨ A) ∧ \\
& (¬D ∨ E ∨ ¬F ∨ B) ∧ (E ∨ ¬A ∨ ¬B ∨ ¬D ∨ F) ∧\\
& (¬A ∨ D) ∧ (¬D ∨ ¬A ∨ D ∨ B) ∧ (¬A ∨ ¬F) ∧\\ 
& (¬D ∨ ¬A ∨ ¬F ∨ B) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F)\\
\end{aligned}$$
**Horn clauses identification:**
1. (C ∨ ¬F) is Horn clause (contains only one positive literals)
2. (¬A ∨ D) is Horn clause (contains only one positive literals)
3. (¬A ∨ ¬F) is Horn clause (contains only one positive literals)
4. (¬D ∨ ¬A ∨ ¬F ∨ B) is Horn clause (contains only one positive literals)
5. (¬A ∨ ¬B ∨ ¬D ∨ F) is Horn clause (contains only one positive literals)


---

$$\phi_3 = ((A ↔ B) ∨ (C → D)) ∧ ((¬A ∨ ¬D) → (F ∧ ¬G))$$
**Converting CNF steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$: 
$$\begin{aligned}
φ₃ = [((¬A ∨ B) ∧ (¬B ∨ A)) ∨ (¬C ∨ D)] ∧ [(A ∧ D) ∨ (F ∧ ¬G)]
\end{aligned}$$
2. CNF: 
$$\begin{aligned}
& \text{Using the distributive law:}\\
& (¬A ∨ B ∨ ¬C ∨ D) ∧ (¬B ∨ A ∨ ¬C ∨ D) ∧\\
&(A ∨ F) ∧ (A ∨ ¬G) ∧ (D ∨ F) ∧ (D ∨ ¬G)\\\\
& \text{Final CNF Result:}\\
& φ₃ = (¬A ∨ B ∨ ¬C ∨ D) ∧(¬B ∨ A ∨ ¬C ∨ D) ∧\\
&(A ∨ F) ∧(A ∨ ¬G) ∧(D ∨ F) ∧(D ∨ ¬G)
\end{aligned}$$
**Horn clauses identification:**
1. (A ∨ ¬G) is Horn clause (contains only one positive literals)
2. (D ∨ ¬G) is Horn clause (contains only one positive literals)

---
## c

---
### i
When F = False, we substitute F = False into φ₂:
$$\begin{aligned}
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ False) ↔ (A ∧ B))\\
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → (¬D ↔ (A ∧ B))\\
\end{aligned}$$
**Effect on satisfiability**: 
The formula becomes more constrained. Setting F = False reduces the search space and may make the formula unsatisfiable if there were satisfying assignments that required F = True

---
### ii
When F = False, we substitute F = False into φ₂:
$$\begin{aligned}
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ False) ↔ (A ∧ B))\\
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → (¬D ↔ (A ∧ B))\\
\end{aligned}$$
If the φ₂ is true, then (¬D ↔ (A ∧ B)) must be true.:

- If ¬D is true (D is false), then (A ∧ B) must be true, so A = True and B = True
- If ¬D is false (D is true), then (A ∧ B) must be false, so either A = False or B = False

**Inference**: When F = False, the satisfiability of φ₂ creates a strong dependency between D, A, and B. The truth values of A and B become constrained by the truth value of D through the biconditional relationship.

---
# Q2
## Q2.1
$$\begin{aligned}
&R1: (P \land T \land NS) \to S\\
&R2: F \to H\\
&R3: H \to T\\
&R4: E \to NS\\
&R5: NS \to P\\
&R6: P \to W\\
&R7: M \to NF\\
&R8: ignored\text{(no symbol for "sneeze in spring" in key)}   \to A\\
&R9: (\lnot T \land \lnot NS) \to (\lnot V \lor W)\\
&R10: (\lnot E \land \lnot T) \to (\lnot NF \lor W)\\
\end{aligned}
$$

---
## Q2.2
Initial facts: 
- The person has a fever
- The person is exhausted

Prove that the person is sick (S):
- $F \; proves \; H \rightarrow TruthList[F,E,H]$
- $H \; proves \; T \rightarrow TruthList[F,E,H,T]$
- $E \; proves \; NS \rightarrow TruthList[F,E,H,T,NS]$
- $NS \; proves \; P \rightarrow TruthList[F,E,H,T,NS,P]$
- $T,NS,P \;proves\; S$
- $so\; F \land E \;proves\;S$

---
## Q2.3
Initial facts: 
- The person has a fever
- The person is exhausted

Prove that the person is sick (S):
- $Goal\; S \; needs \; [P,T,NS] \rightarrow NeedList[P,T,NS]$
- $P \; needs \; NS \rightarrow NeedList[T,NS]$
- $NS \; needs \; E \rightarrow NeedList[T,E]$
- $T \; needs \; H \rightarrow NeedList[H,E]$
- $H \; needs \; F \rightarrow NeedList[F,E]$
- $\text{we already know [F,E], so we can infer S}$

---
## Q2.4
### i
**Answer:**
Yes

**Why?**
Forward chaining can stop early if the algorithm is goal-directed or implemented to terminate when the target atom S is derived. In our run, forward chaining derived S after a finite number of rule applications (R2,R3,R4,R5,R1). Once S is derived, there is no need to continue deriving other consequences (like W from R6). If using a blind saturation strategy (derive all consequences until fixpoint), it would not stop early.

### ii
#### Could adding ¬M improve inference?
**Answer:**
No

**Why?**
Adding $\lnot M$ (i.e. asserting the person does NOT have muscle pain) would only block inferences that require M. If we add $\lnot M$, that prevents deriving NF via $M \rightarrow NF$, but $M \rightarrow NF$ was not needed for deriving S in this scenario. Thus adding $\lnot M$ does not help derive S; it only prevents derivation of NF from M, and thus generally does not improve inference toward S

#### Could adding A improve inference?
**Answer:**
No

**Why?**
Adding $A$ (the person has an allergy) corresponds to the allergy fact. The only rule mentioning $A$ in the provided rules is $ignored \to A$ (which depends on a sneeze-in-spring atom that we do not have). There are no rules that use $A$ to derive P, T, NS, or S. So adding $A$ alone does not help infer S

---
# Q3
## a
### Clause 1
$$∃z. R(z) → ∃w. T(w)$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$¬∃x. R(x) ∨ ∃w. T(w)$$
2. NNF: 
$$\begin{aligned}
&∀x. ¬R(x) ∨ ∃w. T(w)\\
&∀x \;∃w. (¬R(x) ∨ T(w))
\end{aligned}$$
3. Skolemization:
$$ ¬R(x) ∨ T(g\{x\})
$$
4. standardization:
 $$¬R(x) ∨ T(g(x))$$
 
 ---
### Clause 2
$$∀x\: ∃y. (∀z. (P(x) ∨ R(z)) ∧ ∃w. (T(w) → Q(y)))$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$\begin{aligned}
& ∀x \;∃y. (∀z. (P(x) ∨ R(z)) ∧ ∃w. (¬T(w) ∨ Q(y)))\\
& ∀x \;∃y \;∀z \;∃w. ((P(x) ∨ R(z)) ∧ (¬T(w) ∨ Q(y)))
\end{aligned}$$
2. Skolemization: 
$$((P(x) ∨ R(z)) ∧ (¬T(g_3(x,z)) ∨ Q(g_2(x))))$$
3. standardization:
$$(P(x_1) ∨ R(z)) ∧ (¬T(g_3(x_2,z)) ∨ Q(g_2(x_3)))$$

---
### Clause 3
$$∀w \;∃y. (∀x. (P(x) → T(w)) ∧ ∀x. (Q(y) → P(x)))$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$\begin{aligned}
& ∀w \;∃y. (∀x. (¬P(x) ∨ T(w)) ∧ ∀x. (¬Q(y) ∨ P(x)))\\
& ∀w \;∃y\; ∀x_1\; ∀x_2. ((¬P(x_1) ∨ T(w)) ∧ (¬Q(y) ∨ P(x_2)))
\end{aligned}$$
2. Skolemization: 
$$((¬P(x_1) ∨ T(w)) ∧ (¬Q(g_4(w)) ∨ P(x_2)))$$
3. standardization:
$$(¬P(x_1) ∨ T(w_1)) ∧ (¬Q(g_4(w_2)) ∨ P(x_2))$$

---
### Clause 4
$$∀x \;∃z. (¬R(z) ∨ ¬Q(x))
$$
**Converting steps:**
1. Skolemization: 
$$(¬R(g_5(x)) ∨ ¬Q(x))$$
2. standardization:
$$¬R(g_5(x)) ∨ ¬Q(x)$$

---
### Clause 5
$$∀x. (U(x) → (P(x) ∨ ¬T(f(x))))
$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$∀x. (¬U(x) ∨ P(x) ∨ ¬T(f(x)))$$
2. standardization:
$$¬U(x) ∨ P(x) ∨ ¬T(f(x))$$

---
### Clause 6
$$∃x. (Q(x) ∧ ¬U(x))
$$
**Converting steps:**
1. Skolemization: 
$$Q(c) ∧ ¬U(c)$$
2. standardization:
$$Q(c_1) ∧ ¬U(c_2)$$

---
### Clause 7
$$∀x \;∀y. (¬P(x) ∨ Q(y) ∨ S(x, y))
$$
**Converting steps:**
1. standardization:
$$¬P(x) ∨ Q(y) ∨ S(x, y)$$

---
## b
To prove `∀x. P(x)`, we need to refute `¬∀x. P(x) ≡ ∃x. ¬P(x)`

**Skolemize with new constant c:** add $¬P(c)$ into KB

**KB:**
- $¬R(x) ∨ T(g₁(x))$
- $P(x) ∨ R(z)$
- $¬T(g₃(x,z)) ∨ Q(g₂(x))$
- $¬P(x₁) ∨ T(w)$
- $¬Q(g₄(w)) ∨ P(x₂)$
- $¬R(g₅(x)) ∨ ¬Q(x)$
- $¬U(x) ∨ P(x) ∨ ¬T(f(x))$
- $Q(a)$
- $¬U(a)$
- $¬P(x) ∨ Q(y) ∨ S(x, y)$
- $¬P(c)$

**Resolution steps:**
**Step 1** 
instantiate $¬R(g₅(x)) ∨ ¬Q(x)$ using $x = a$
so we can get $¬R(g₅(a)) ∨ ¬Q(a)$

**Step 2** 
instantiate $P(x) ∨ R(z)$ with $z := g₅(a)$
so we can get $P(x) ∨ R(g₅(a))$

**Step 3** 
resolve $¬R(g₅(a)) ∨ ¬Q(a)$ with $Q(a)$
so we can get $¬R(g₅(a))$

**Step 4**
resolve $P(x) ∨ R(g₅(a))$ with $¬R(g₅(a))$
so we can get $P(x)$

**Step 4**
instantiate $P(x)$ using $x = c$
so we can get $P(c)$

**Step 5**
resolve $P(c)$ with $¬P(c)$
so we can get **NIL**

**Conclusion:** 
We have derived a contradiction. Therefore the negation of the goal is unsatisfiable with the knowledge base; hence the KB entails $∀x P(x)$

---
## c
### i
A clause is _redundant_ if it can be derived from other clauses (or its removal does not affect provability of the goal)

- $¬P(x) ∨ Q(y) ∨ S(x, y)$ is not needed for the derivation above **Q-b**; the proof did not use $S$ or clause $¬P(x) ∨ Q(y) ∨ S(x, y)$. So $¬P(x) ∨ Q(y) ∨ S(x, y)$ is redundant with respect to proving $∀x P(x)$
    
- $¬P(x₁) ∨ T(w)$ and $¬Q(g₄(w)) ∨ P(x₂)$ were also not used in the short refutation above **Q-b**
    
- $¬R(x) ∨ T(g₁(x))$ and $¬T(g₃(x,z)) ∨ Q(g₂(x))$ were also not required in the minimal proof given. So for the particular proof of $∀x P(x)$, these clauses are effectively redundant.

### ii
Clauses that increase complexity generally are those that:

- introduce many variables(e.g. clauses with two universal variables like $¬P(x) ∨ Q(y) ∨ S(x,y)$ 
- introduce Skolem functions (not just constants), which generate infinitely many terms under instantiation (e.g. $g₁(x)$, $g₃(x,z)$, $g₄(w)$, and $g₂(x)$)

Concretely:
- Clauses with Skolem functions ($P(x) ∨ R(z)$, $¬Q(g₄(w)) ∨ P(x₂)$, $¬R(g₅(x)) ∨ ¬Q(x)$) increase search-space complexity because resolution can create many different instances with terms like $g₂(x)$, $g₃(x,z)$, $g₄(w)$, $g₅(x)$
    - $¬T(g₃(x,z)) ∨ Q(g₂(x))$ and $¬Q(g₄(w)) ∨ P(x₂)$ are particularly problematic because they chain function terms and can cause a combinatorial explosion in instantiation.
        
- $¬P(x) ∨ Q(y) ∨ S(x, y)$ is a binary relation clause with two universally quantified variables — it increases the number of pairwise combinations during grounding/resolution and so adds combinatorial complexity
    
- $P(x) ∨ R(z)$ by itself is simple, but because it involves two different variables $x$ and $z$ and interacts with other skolem-derived facts, it participates in cross-instantiation that can blow up the search if there are many candidate terms

So the primary complexity drivers: **Skolem functions** and **clauses with multiple universally quantified variables**

---
## d
C6a:  Q(a)
C6b:  ¬U(a)

**Conclusion:** 
Yes

**Why?**
In the resolution proof above, the crucial starting fact was $Q(a)$. We used $Q(a)$ to obtain $R(g₅(a))$ which then allowed us to resolve $P(x) ∨ R(g₅(a))$ into $P(x)$, and finally get $P(c)$ to contradict $¬P(c)$

If clause 6 $(\exists x \;Q(x) \land ¬U(a))$ is removed, we lose the witness $a$ with $Q(a)$. In that case:
- We can no longer instantiate $¬R(g₅(a)) ∨ ¬Q(a)$ with $x = a$ to derive a particular $¬R(g₅(a))$
The removal of clause 6 would likely make G unprovable from the remaining clauses, as it eliminates key ground terms needed for the resolution process