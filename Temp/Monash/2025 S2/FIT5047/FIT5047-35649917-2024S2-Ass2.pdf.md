# Q1
## a
$$\phi_1 = (((A ∨ (B → C)) ∧ (¬C ∨ D)) → ((A → D) ∨ (C ↔ E)))$$
**Conclusion:**
satisfiable but not valid

**Justification:**
- if `A = true, D = true`, then the equivalence holds
- if `A = true, D = false, C = false, E =true`, then the equivalence fails

---

$$\phi_2 = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ F) ↔ (A ∧ B))$$
**Conclusion:**
satisfiable but not valid

**Justification:**
- If `A = true, B = true, C = flase, D = false, F = false`, the equivalence fails
- If `A = true, B = true, D = false, F = true`, the equivalence holds

---

$$\phi_3 = ((A ↔ B) ∨ (C → D)) ∧ ((¬A ∨ ¬D) → (F ∧ ¬G))$$
**Conclusion:**
satisfiable but not valid

**Justification:**
- If `A = true, D = false`, the equivalence fails
- If `F = true, G = false`, the equivalence holds

---
## b

$$\phi_1 = (((A ∨ (B → C)) ∧ (¬C ∨ D)) → ((A → D) ∨ (C ↔ E)))$$
**Converting CNF steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$: 
$$\lnot \left( \left[ A \lor (\lnot B \lor C) \right] \land (\lnot C \lor D) \right) \lor \left( (\lnot A \lor D) \lor \left[ (\lnot C \land E) \lor ( C \land \lnot E) \right] \right)$$
2. CNF: 
$$\begin{aligned}
&φ₁ = [¬(A ∨ ¬B ∨ C) ∨ ¬(¬C ∨ D)] ∨ [(¬A ∨ D ∨ ¬C ∨ E) ∧ (¬A ∨ D ∨ ¬E ∨ C)]\\
&φ₁ = [(¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)] ∨ [(¬A ∨ D ∨ ¬C ∨ E) ∧ (¬A ∨ D ∨ ¬E ∨ C)]\\\\

& \text{if we assume:}\\
& A₁ = (¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)\\
& B₁ = (¬A ∨ D ∨ ¬C ∨ E)\\
& B₂ = (¬A ∨ D ∨ ¬E ∨ C)\\
& \text{So we have:}\; φ₁ = A₁ ∨ (B₁ ∧ B₂)\\\\
& \text{Using the distributive law:}\; φ₁ = (A₁ ∨ B₁) ∧ (A₁ ∨ B₂)\\
& φ₁ = [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬C ∨ E)] ∧\\
& [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬E ∨ C)]\\\\

& φ₁ = [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬C ∨ E)] ∧\\
& [((¬A ∧ B ∧ ¬C) ∨ (C ∧ ¬D)) ∨ (¬A ∨ D ∨ ¬E ∨ C)]\\\\\\

& \text{Final CNF Result:}φ₁ = (¬A ∨ B ∨ D ∨ E) ∧ (¬A ∨ D ∨ ¬E ∨ C) ∧ (¬A ∨ ¬C ∨ E)
\end{aligned}$$
**Horn clauses identification:**
1. (¬A ∨ ¬C ∨ E) is Horn clause (contains only one positive literals)

---

$$\phi_2 = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ F) ↔ (A ∧ B))$$
**Converting CNF steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$: 
$$\begin{aligned}
& φ₂ = (((¬A ∧ B) ∨ (¬C ∨ D)) ∧ (¬E ∨ A)) → \\
& (((¬D ∨ F) → (A ∧ B)) ∧ ((A ∧ B) → (¬D ∨ F)))\\\\

&φ₂ = ¬(((¬A ∧ B) ∨ (¬C ∨ D)) ∧ (¬E ∨ A)) ∨ \\
&(((D ∧ ¬F) ∨ (A ∧ B)) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F))\\
\end{aligned}$$
2. CNF: 
$$\begin{aligned}
& \text{Using the De Morgan's law:}\\
& φ₂ = (((A ∨ ¬B) ∧ (C ∧ ¬D)) ∨ (E ∧ ¬A)) ∨ \\
& (((D ∧ ¬F) ∨ (A ∧ B)) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F)) \\\\

& \text{Using the distributive law:}\\
& [(A ∨ ¬B ∨ E) ∧ (A ∨ ¬B ∨ ¬A) ∧ (C ∨ E) ∧ (C ∨ ¬A) ∧ (¬D ∨ E) ∧ (¬D ∨ ¬A)] ∨\\
& [(D ∨ A) ∧ (D ∨ B) ∧ (¬F ∨ A) ∧ (¬F ∨ B) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F)]\\\\

& \text{Final CNF Result:}\\
& φ₂ = (A ∨ ¬B ∨ E ∨ D) ∧ (A ∨ E ∨ D ∨ B) ∧ (A ∨ ¬B ∨ E ∨ ¬F) ∧ \\
& (A ∨ E ∨ ¬F ∨ B) ∧ (¬B ∨ E ∨ ¬A ∨ ¬D ∨ F) ∧\\
& (C ∨ E ∨ D ∨ A) ∧ (C ∨ E ∨ D ∨ B) ∧ (C ∨ E ∨ ¬F ∨ A) ∧ \\
& (C ∨ E ∨ ¬F ∨ B) ∧ (C ∨ E ∨ ¬A ∨ ¬B ∨ ¬D ∨ F) ∧\\
& (C ∨ D) ∧ (C ∨ ¬A ∨ D ∨ B) ∧ (C ∨ ¬F) ∧ \\
& (C ∨ ¬A ∨ ¬F ∨ B) ∧ (C ∨ ¬A ∨ ¬B ∨ ¬D ∨ F) ∧\\
& (E ∨ A) ∧ (E ∨ D ∨ B) ∧ (¬D ∨ E ∨ ¬F ∨ A) ∧ \\
& (¬D ∨ E ∨ ¬F ∨ B) ∧ (E ∨ ¬A ∨ ¬B ∨ ¬D ∨ F) ∧\\
& (¬A ∨ D) ∧ (¬D ∨ ¬A ∨ D ∨ B) ∧ (¬A ∨ ¬F) ∧\\ 
& (¬D ∨ ¬A ∨ ¬F ∨ B) ∧ (¬A ∨ ¬B ∨ ¬D ∨ F)\\
\end{aligned}$$
**Horn clauses identification:**
1. (C ∨ ¬F) is Horn clause (contains only one positive literals)
2. (¬A ∨ D) is Horn clause (contains only one positive literals)
3. (¬A ∨ ¬F) is Horn clause (contains only one positive literals)
4. (¬D ∨ ¬A ∨ ¬F ∨ B) is Horn clause (contains only one positive literals)
5. (¬A ∨ ¬B ∨ ¬D ∨ F) is Horn clause (contains only one positive literals)


---

$$\phi_3 = ((A ↔ B) ∨ (C → D)) ∧ ((¬A ∨ ¬D) → (F ∧ ¬G))$$
**Converting CNF steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$: 
$$\begin{aligned}
φ₃ = [((¬A ∨ B) ∧ (¬B ∨ A)) ∨ (¬C ∨ D)] ∧ [(A ∧ D) ∨ (F ∧ ¬G)]
\end{aligned}$$
2. CNF: 
$$\begin{aligned}
& \text{Using the distributive law:}\\
& (¬A ∨ B ∨ ¬C ∨ D) ∧ (¬B ∨ A ∨ ¬C ∨ D) ∧ (A ∨ F) ∧ (A ∨ ¬G) ∧ (D ∨ F) ∧ (D ∨ ¬G)\\\\

& \text{Final CNF Result:}\\
& φ₃ = (¬A ∨ B ∨ ¬C ∨ D) ∧
(¬B ∨ A ∨ ¬C ∨ D) ∧(A ∨ F) ∧(A ∨ ¬G) ∧(D ∨ F) ∧(D ∨ ¬G)
\end{aligned}$$
**Horn clauses identification:**
1. (A ∨ ¬G) is Horn clause (contains only one positive literals)
2. (D ∨ ¬G) is Horn clause (contains only one positive literals)

---
## c

---
### i
When F = False, we substitute F = False into φ₂:
$$\begin{aligned}
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ False) ↔ (A ∧ B))\\
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → (¬D ↔ (A ∧ B))\\
\end{aligned}$$
**Effect on satisfiability**: 
The formula becomes more constrained. Setting F = False reduces the search space and may make the formula unsatisfiable if there were satisfying assignments that required F = True

---
### ii
When F = False, we substitute F = False into φ₂:
$$\begin{aligned}
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → ((¬D ∨ False) ↔ (A ∧ B))\\
& φ₂ = (((¬A ∧ B) ∨ (C → D)) ∧ (¬E ∨ A)) → (¬D ↔ (A ∧ B))\\
\end{aligned}$$
If the φ₂ is true, then (¬D ↔ (A ∧ B)) must be true.:

- If ¬D is true (D is false), then (A ∧ B) must be true, so A = True and B = True
- If ¬D is false (D is true), then (A ∧ B) must be false, so either A = False or B = False

**Inference**: When F = False, the satisfiability of φ₂ creates a strong dependency between D, A, and B. The truth values of A and B become constrained by the truth value of D through the biconditional relationship.

---
# Q2
## Q2.1
$$\begin{aligned}
&R1: (P \land T \land NS) \to S\\
&R2: F \to H\\
&R3: H \to T\\
&R4: E \to NS\\
&R5: NS \to P\\
&R6: P \to W\\
&R7: M \to NF\\
&R8: ignored\text{(no symbol for "sneeze in spring" in key)}   \to A\\
&R9: (\lnot T \land \lnot NS) \to (\lnot V \lor W)\\
&R10: (\lnot E \land \lnot T) \to (\lnot NF \lor W)\\
\end{aligned}
$$

---
## Q2.2
Initial facts (observations): 
- The person has a fever
- The person is exhausted

Prove that the person is sick (S):
- $F \; proves \; H \rightarrow TruthList[F,E,H]$
- $H \; proves \; T \rightarrow TruthList[F,E,H,T]$
- $E \; proves \; NS \rightarrow TruthList[F,E,H,T,NS]$
- $NS \; proves \; P \rightarrow TruthList[F,E,H,T,NS,P]$
- $T,NS,P \;proves\; S$
- $so\; F \land E \;proves\;S$

---
## Q2.3
Initial facts (observations): 
- The person has a fever
- The person is exhausted

Prove that the person is sick (S):
- $Goal\; S \; needs \; [P,T,NS] \rightarrow NeedList[P,T,NS]$
- $P \; needs \; NS \rightarrow NeedList[T,NS]$
- $NS \; needs \; E \rightarrow NeedList[T,E]$
- $T \; needs \; H \rightarrow NeedList[H,E]$
- $H \; needs \; F \rightarrow NeedList[F,E]$
- $\text{we already know [F,E], so we can infer S}$

---
## Q2.4
### i
**Answer:**
Yes

**Why?**
Forward chaining can stop early if the algorithm is goal-directed or implemented to terminate when the target atom S is derived. In our run, forward chaining derived S after a finite number of rule applications (R2,R3,R4,R5,R1). Once S is derived, there is no need to continue deriving other consequences (like W from R6). If using a blind saturation strategy (derive all consequences until fixpoint), it would not stop early.

### ii
#### Could adding ¬M improve inference?
**Answer:**
No

**Why?**
Adding $\lnot M$ (i.e. asserting the person does NOT have muscle pain) would only block inferences that require M. Rule R7 is $M \rightarrow NF$ (muscle pain implies not feeling well). If we add $\lnot M$, that prevents deriving NF via R7, but R7 was not needed for deriving S in this scenario. Thus adding $\lnot M$ does not help derive S; it only prevents derivation of NF from M, and thus generally does not improve inference toward S

#### Could adding A improve inference?
**Answer:**
No
**Why?**
Adding $A$ (the person has an allergy) corresponds to the allergy atom. The only rule mentioning $A$ in the provided rules is R8 (which depends on a sneeze-in-spring atom that we do not have). There are no rules that use $A$ to derive P, T, NS, or S. So adding $A$ alone does not help infer S.

---
# Q3
## a
### Clause 1
$$∃z. R(z) → ∃w. T(w)$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$¬∃x. R(x) ∨ ∃w. T(w)$$
2. NNF: 
$$\begin{aligned}
&∀x. ¬R(x) ∨ ∃w. T(w)\\
&∀x \;∃w. (¬R(x) ∨ T(w))
\end{aligned}$$
3. Skolemization:
$$ ¬R(x) ∨ T(g\{x\})
$$
4. standardization:
 $$¬R(x_1) ∨ T(g(x_2))$$
 
 ---
### Clause 2
$$∀x\: ∃y. (∀z. (P(x) ∨ R(z)) ∧ ∃w. (T(w) → Q(y)))$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$\begin{aligned}
& ∀x \;∃y. (∀z. (P(x) ∨ R(z)) ∧ ∃w. (¬T(w) ∨ Q(y)))\\
& ∀x \;∃y \;∀z \;∃w. ((P(x) ∨ R(z)) ∧ (¬T(w) ∨ Q(y)))
\end{aligned}$$
2. Skolemization: 
$$((P(x) ∨ R(z)) ∧ (¬T(g_3(x,z)) ∨ Q(g_2(x))))$$
3. standardization:
$$(P(x_1) ∨ R(z)) ∧ (¬T(g_3(x_2,z)) ∨ Q(g_2(x_3)))$$

---
### Clause 3
$$∀w \;∃y. (∀x. (P(x) → T(w)) ∧ ∀x. (Q(y) → P(x)))$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$\begin{aligned}
& ∀w \;∃y. (∀x. (¬P(x) ∨ T(w)) ∧ ∀x. (¬Q(y) ∨ P(x)))\\
& ∀w \;∃y\; ∀x_1\; ∀x_2. ((¬P(x_1) ∨ T(w)) ∧ (¬Q(y) ∨ P(x_2)))
\end{aligned}$$
2. Skolemization: 
$$((¬P(x_1) ∨ T(w)) ∧ (¬Q(g_4(w)) ∨ P(x_2)))$$
3. standardization:
$$(¬P(x_1) ∨ T(w_1)) ∧ (¬Q(g_4(w_2)) ∨ P(x_2))$$

---
### Clause 4
$$∀x \;∃z. (¬R(z) ∨ ¬Q(x))
$$
**Converting steps:**
1. Skolemization: 
$$(¬R(g_5(x)) ∨ ¬Q(x))$$
2. standardization:
$$¬R(g_5(x_1)) ∨ ¬Q(x_2)$$

---
### Clause 5
$$∀x. (U(x) → (P(x) ∨ ¬T(f(x))))
$$
**Converting steps:**
1. eliminate $\rightarrow \text{and} \leftrightarrow$:
$$∀x. (¬U(x) ∨ P(x) ∨ ¬T(f(x)))$$
2. standardization:
$$¬U(x_1) ∨ P(x_2) ∨ ¬T(f(x_3))$$

---
### Clause 6
$$∃x. (Q(x) ∧ ¬U(x))
$$
**Converting steps:**
1. Skolemization: 
$$Q(c) ∧ ¬U(c)$$
2. standardization:
$$Q(c_1) ∧ ¬U(c_2)$$

---
### Clause 7
$$∀x \;∀y. (¬P(x) ∨ Q(y) ∨ S(x, y))
$$
**Converting steps:**
1. standardization:
$$¬P(x_1) ∨ Q(y_1) ∨ S(x_2, y_2)$$

---
## b
To prove `∀x. P(x)`, we need to refute `¬∀x. P(x) ≡ ∃x. ¬P(x)`

**assume a negation of the goal:** `¬P(b)` where b is a constant

**Resolution steps:**

**Step 1:** Derive $Q(a)$ with $¬R(g₅(x)) ∨ ¬Q(x)$
- Unify: $x = a$
- Key that we do not know: $¬R(g_5(a))$

**Step 2:** Derive `¬R(g₅(a))` with $¬R(x) ∨ T(g₁(x))$
- Unify: $x = g_5(a)$
- Key that we do not know: $T(g_1(g_5(a)))$

**Step 3:** Derive $T(g_1(g_5(a)))$ with $¬T(g_3(x,z)) ∨ Q(g_2(x))$
- Unify: $g_3(x,z) = g_1(g_5(a))$
- This requires unification that may not be possible directly

**Alternative approach:** Try to derive `P(b)` to contradict `¬P(b)`

**Step 4:** From clause 9 `¬U(a)` and clause 7 `¬U(x) ∨ P(x) ∨ ¬T(f(x))`

- Unify: x = a
- Key that we do not know: `P(a) ∨ ¬T(f(a))`

**Step 5:** Use clause 5 `¬Q(g₄(w)) ∨ P(x₂)` with appropriate substitutions...

The resolution process is complex and requires careful unification. The goal appears to be **refutable** rather than provable, as we cannot derive a contradiction from the negated goal.

---
## c
### i
A clause is _redundant_ if it can be derived from other clauses (or its removal does not affect provability of the goal).

- **C7 (`¬P(x) ∨ Q(y) ∨ S(x,y)`)** is _not needed_ for the derivation above; the proof did not use `S` or clause `C7`. So `C7` is redundant **with respect to proving** `∀x P(x)`.
    
- **C3a (`¬P(x) ∨ T(w)`)** and **C3b (`¬Q(f3(w)) ∨ P(x)`)** were also not used in the short refutation above. Depending on the rest of KB semantics, some of these may be redundant for the specific goal. In particular, we did not need `C3b` or `C3a` in the derivation.
    
- **C1 (`¬R(x) ∨ T(c1)`)** and **C2b (`¬T(g2(x)) ∨ Q(f2(x))`)** were also not required in the minimal proof given. So for the particular proof of `∀x P(x)`, these clauses are effectively redundant.

### ii
Clauses that increase complexity generally are those that:

- introduce many variables or arities (e.g. clauses with two universal variables like `C7: ¬P(x) ∨ Q(y) ∨ S(x,y)`), and
    
- introduce Skolem **functions** (not just constants), which generate infinitely many ground terms under instantiation — e.g. `f2(x)`, `g2(x)`, `f3(w)`, and `f4(x)`.
    

Concretely:

- **Clauses with Skolem functions** (`C2b`, `C3b`, `C4`) increase search-space complexity because resolution can create many different ground instances with terms like `f2(t)`, `g2(t)`, `f3(t)`, `f4(t)` for many `t`.
    
    - `C2b: ¬T(g2(x)) ∨ Q(f2(x))` and `C3b: ¬Q(f3(w)) ∨ P(x)` are particularly problematic because they chain function terms and can cause a combinatorial explosion in unification/instantiation.
        
- **Clause 7 (`C7: ¬P(x) ∨ Q(y) ∨ S(x,y)`)** is a binary relation `S(x,y)` clause with two universally quantified variables — it increases the number of pairwise combinations during grounding/resolution and so adds combinatorial complexity.
    
- **Clause 2a (`P(x) ∨ R(z)`)** by itself is simple, but because it involves two different variables `x` and `z` and interacts with other existential/skolem-derived facts, it participates in cross-instantiation that can blow up the search if there are many candidate ground terms.
    

So the primary complexity drivers: **Skolem functions** and **clauses with multiple universally quantified variables / predicate arities**.

---
## d
C6a:  Q(a)
C6b:  ¬U(a)

**Conclusion:** 
Yes

In the resolution proof above, the crucial starting fact was `Q(a)` (C6a). We used `Q(a)` to obtain `¬R(f4(a))` (via C4) which then allowed us to resolve `P(x) ∨ R(f4(a))` into `P(x)` (via C2a), and finally get `P(b)` to contradict `¬P(b)`.

If **clause 6 is removed**, we lose the _witness_ `a` with `Q(a)`. In that case:

- We can no longer instantiate `C4` with `x = a` to derive a particular `¬R(f4(a))`.
    
- Without any ground `Q(t)` fact, `C4` (which is `¬R(f4(x)) ∨ ¬Q(x)`) does not automatically give us a ground `¬R(...)` fact; it only says for each `x` either `¬R(f4(x))` or `¬Q(x)` holds, but without a concrete `Q(x)` we cannot force the `¬R(...)` disjunct.
    
- Therefore, the short refutation above fails: there is no guaranteed way to obtain a concrete `¬R(z0)` to feed into `C2a` and produce a universal `P(x)`.
