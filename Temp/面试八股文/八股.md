---
date: 2025-10-16
author:
  - Siyuan Liu
tags:
  - 八股
---
1. Accelerate
2. DeepSpeed
3. SFT
4. GRPO
5. RLHF
6. Llama
7. RL
8. Prompt工程
9. AIGC
10. 熟悉扩散模型优化技术（如步数蒸馏，高效模型结构设计）、模型优化（如量化、剪枝、稀疏化）、推理加速（如算子优化、分布式推理、多卡并行等）
11. CP和UDP的区别是什么？应用场景是什么？
12. http和https的区别？
13. https数字证书交换的过程详细说一下？
14. TCP握手详细过程
15. 什么是MHA
16. Attention运算公式
17. 为什么除以根号dk
18. 介绍现有相对位置编码和绝对位置编码的异同点，都有哪些结构
19. RoPE的结构
20. RoPE相比于绝对位置编码的优势是什么？为什么外推性更好？
21. 为什么RoPE理论上可以无限外推？
22. RoPE为什么可以利用绝对位置和相对位置的优势？
23. 介绍RAG项目（基座模型是什么？几b ？全参微调用了多少卡？数据多大？问答对的形式有图片吗？
24. 对RAG的理解是什么？为什么要用RAG？
25. BGE模型的结构
26. 什么是LoRA？有个两层神经网络，参数1万*一万，低秩r =100， LoRA参数量是多少？
27. 为什么用KV Cache？
28. KV Cache有哪些优化方法？
29. 文生图/图生文结构了解吗？文生图的怎么解码的
30. CLIP了解吗？
31. Deepseek MOE架构路由机制的细节
32. 自我介绍
33. 论文拷打，提出质疑
34. RAG项目介绍
35. 分块的策略是什么
36. PDF的表格和图片怎么解析的？图片和表格的信息丢失了怎么办？
37. RAG的关键词检索和重排细节
38. 异构图方式和传统的多模态拼接方式有什么性能上的改进吗？
39. 多模态之间的特征的对齐你是怎么做的？现有工作怎么做的
40. Prompt有什么系统性优化的方法？
41. 简单介绍一下Prefix Cache ? Deepseek 是怎么开启Prefix Cache的？
42. 位置编码的作用的实现方式有哪些？
43. LLM推理部署的时候，会用vLLM, 这主要从哪些方面提升？怎么提升的推理速度？
44. 文本生成解码策略，贪心搜索和束搜索的优劣是什么？
45. RAG项目400万文字怎么分块，索引，embedding的
46. 微调的指标和RAG的指标是什么？ROUGE指标怎么计算
47. 评估方式是不是太简单了，对SFT的指标还有没有更好的
48. 项目中负责的部分
49. 用的最多的GPU时间是多少
50. 有做过多机多卡训练吗
51. 为什么去前端实习了后又转算法
52. 对未来的规划是什么，想做什么技术
53. 实验室的方向是什么
54. 大模型的预训练和SFT的不同是什么
55. 限制大模型输入长度的因素有哪些？
56. 目前的大模型如何解决长上下文？